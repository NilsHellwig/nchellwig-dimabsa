{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509021e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBTASKS = [2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4439be12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from IPython.display import display\n",
    "from helper import *\n",
    "from evaluate import *\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cf5abf",
   "metadata": {},
   "source": [
    "## Export Predictions in Valid Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e76efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "STRATEGIES = [\"dev-train\", \"test-train_dev\"]\n",
    "LLMS = [\"unsloth/gemma-3-27b-it-bnb-4bit\"]\n",
    "NUM_SC = [None, 5, 10, 15]\n",
    "METHODS =  [\"no_sc_guided\", \"no_sc_no_guided\", \"sc_guided\", \"sc_no_guided\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670e35a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "        # results.append({\n",
    "        #     \"no_sc_guided\": evaluate_predictions(labels_filtered, preds_no_sc_guided, task=subtask),\n",
    "        #     \"no_sc_no_guided\": evaluate_predictions(labels_filtered, preds_no_sc_no_guided, task=subtask),\n",
    "        #     \"sc_guided\": evaluate_predictions(labels_filtered, preds_sc_guided, task=subtask),\n",
    "        #     \"sc_no_guided\": evaluate_predictions(labels_filtered, preds_sc_no_guided, task=subtask),\n",
    "        # })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4627ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for strategy in STRATEGIES:\n",
    "    for llm in LLMS:\n",
    "        for num_sc in NUM_SC:\n",
    "            for method in METHODS:\n",
    "                for subtask in SUBTASKS:\n",
    "                    for language, domain in VALID_LANGUAGES_DOMAINS:\n",
    "                        predictions = get_performance(language,\n",
    "                                                      domain,\n",
    "                                                      subtask,\n",
    "                                                      strategy,\n",
    "                                                      llm=llm, num_preds_sc=num_sc if num_sc is not None else 5)[1][method]\n",
    "\n",
    "                        output_dir = f\"exported_predictions/{strategy}/{llm.replace('/', '_')}/{num_sc}/{method}/subtask_{subtask}/pred_{language}_{domain}.jsonl\"\n",
    "                        os.makedirs(os.path.dirname(output_dir), exist_ok=True)\n",
    "                        with open(output_dir, \"w\", encoding=\"utf-8\") as f:\n",
    "                            for pred in predictions:\n",
    "                                f.write(json.dumps(\n",
    "                                    pred, ensure_ascii=False) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7ab978",
   "metadata": {},
   "source": [
    "## Create Tables Dataset Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fc743f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ROWS = [\"train\", \"dev\", \"test\"]\n",
    "DOMAIN_ORDER = [\"restaurant\", \"laptop\", \"hotel\"]  # Definiere die gewünschte Reihenfolge\n",
    "SUBTASK_ORDER = [2, 3]  # Erst Subtask 2, dann Subtask 3\n",
    "\n",
    "records_dataset_statistics = []\n",
    "\n",
    "for subtask in SUBTASKS:\n",
    "    for language, domain in VALID_LANGUAGES_DOMAINS:\n",
    "\n",
    "        # train + dev\n",
    "        for split in [\"train\", \"dev\"]:\n",
    "            count = len(get_dataset(subtask, language, domain, split=split))\n",
    "            records_dataset_statistics.append((split, domain, subtask, language, count))\n",
    "\n",
    "        # test (optional)\n",
    "        try:\n",
    "            count_test = len(get_dataset(subtask, language, domain, split=\"test\"))\n",
    "            records_dataset_statistics.append((\"test\", domain, subtask, language, count_test))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # # test_cross_validation (als ganze Zahl)\n",
    "        # train_size = len(get_dataset(subtask, language, domain, split=\"train\"))\n",
    "        # records_dataset_statistics.append((\n",
    "        #     \"test_cross_validation\",\n",
    "        #     domain,\n",
    "        #     subtask,\n",
    "        #     language,\n",
    "        #     str(int(train_size * 0.2))\n",
    "        # ))\n",
    "\n",
    "df_dataset_statistics = pd.DataFrame(\n",
    "    records_dataset_statistics,\n",
    "    columns=[\"split\", \"domain\", \"subtask\", \"language\", \"count\"]\n",
    ")\n",
    "\n",
    "# Konvertiere domain zu Categorical mit gewünschter Reihenfolge\n",
    "df_dataset_statistics[\"domain\"] = pd.Categorical(\n",
    "    df_dataset_statistics[\"domain\"], \n",
    "    categories=DOMAIN_ORDER, \n",
    "    ordered=True\n",
    ")\n",
    "\n",
    "df_dataset_statistics = (\n",
    "    df_dataset_statistics\n",
    "        .pivot(index=[\"split\", \"domain\"],\n",
    "               columns=[\"subtask\", \"language\"],\n",
    "               values=\"count\")\n",
    "        .sort_index(level=[\"split\", \"domain\"], key=lambda x: x.map({s: i for i, s in enumerate(ROWS)} if x.name == \"split\" else {d: i for i, d in enumerate(DOMAIN_ORDER)}))\n",
    ")\n",
    "\n",
    "# Spalten nach gewünschter Subtask-Reihenfolge sortieren (erst 2, dann 3)\n",
    "df_dataset_statistics = df_dataset_statistics.reindex(\n",
    "    columns=sorted(df_dataset_statistics.columns, key=lambda x: (SUBTASK_ORDER.index(x[0]), x[1]))\n",
    ")\n",
    "\n",
    "df_dataset_statistics = df_dataset_statistics.applymap(\n",
    "    lambda x: f\"{int(x):,}\" if pd.notna(x) else \"-\"\n",
    ")\n",
    "\n",
    "# get values from left to right from top to bottom as 1D list\n",
    "values_list_dataset_statistics = df_dataset_statistics.values.flatten().tolist()\n",
    "df_dataset_statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9ab0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"plots/muster/dataset.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    dataset_muster = f.read()\n",
    "\n",
    "# gehe von xxxx zu xxxx und trage die Werte ein\n",
    "for value in values_list_dataset_statistics:\n",
    "    dataset_muster = dataset_muster.replace(\"xxxx\", value, 1)\n",
    "\n",
    "with open(\"plots/dataset_statistics.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(dataset_muster)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vllm013",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
