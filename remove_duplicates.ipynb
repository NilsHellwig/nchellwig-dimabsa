{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8254610",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def remove_duplicates_from_file(filepath):\n",
    "    \"\"\"Remove duplicate quadruplets or triplets from a JSONL file.\"\"\"\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        data = [json.loads(line) for line in f]\n",
    "    \n",
    "    cleaned_data = []\n",
    "    total_removed = 0\n",
    "    \n",
    "    for entry in data:\n",
    "        if \"Quadruplet\" in entry:\n",
    "            # Subtask 3: Remove duplicate quadruplets based on Aspect, Category, Opinion (ignore VA)\n",
    "            original_count = len(entry[\"Quadruplet\"])\n",
    "            # Convert to tuples for deduplication\n",
    "            unique_quads = []\n",
    "            seen = set()\n",
    "            for quad in entry[\"Quadruplet\"]:\n",
    "                quad_tuple = (quad[\"Aspect\"], quad[\"Category\"], quad[\"Opinion\"])\n",
    "                if quad_tuple not in seen:\n",
    "                    seen.add(quad_tuple)\n",
    "                    unique_quads.append(quad)\n",
    "            entry[\"Quadruplet\"] = unique_quads\n",
    "            removed = original_count - len(unique_quads)\n",
    "            total_removed += removed\n",
    "            \n",
    "        elif \"Triplet\" in entry:\n",
    "            # Subtask 2: Remove duplicate triplets based on Aspect, Opinion (ignore VA)\n",
    "            original_count = len(entry[\"Triplet\"])\n",
    "            # Convert to tuples for deduplication\n",
    "            unique_trips = []\n",
    "            seen = set()\n",
    "            for trip in entry[\"Triplet\"]:\n",
    "                trip_tuple = (trip[\"Aspect\"], trip[\"Opinion\"])\n",
    "                if trip_tuple not in seen:\n",
    "                    seen.add(trip_tuple)\n",
    "                    unique_trips.append(trip)\n",
    "            entry[\"Triplet\"] = unique_trips\n",
    "            removed = original_count - len(unique_trips)\n",
    "            total_removed += removed\n",
    "        \n",
    "        cleaned_data.append(entry)\n",
    "    \n",
    "    # Write back to file with UTF-8 encoding and ensure_ascii=False\n",
    "    with open(filepath, 'w', encoding='utf-8') as f:\n",
    "        for entry in cleaned_data:\n",
    "            f.write(json.dumps(entry, ensure_ascii=False) + '\\n')\n",
    "    \n",
    "    return total_removed\n",
    "\n",
    "# Process all JSONL files in results/results_pred_dev/\n",
    "base_dir = Path(\"results/results_pred_dev\")\n",
    "\n",
    "for subtask in [2, 3]:\n",
    "    subtask_dir = base_dir / f\"subtask_{subtask}\"\n",
    "    \n",
    "    if not subtask_dir.exists():\n",
    "        print(f\"Directory {subtask_dir} does not exist, skipping...\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Processing Subtask {subtask}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    for filepath in subtask_dir.glob(\"*.jsonl\"):\n",
    "        total_removed = remove_duplicates_from_file(filepath)\n",
    "        if total_removed > 0:\n",
    "            print(f\"✓ {filepath.name}: Removed {total_removed} duplicates\")\n",
    "        else:\n",
    "            print(f\"✓ {filepath.name}: No duplicates found\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"Duplicate removal completed!\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45aaafcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vllm import LLM, SamplingParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8326ad81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vllm.sampling_params import StructuredOutputsParams\n",
    "\n",
    "llm = LLM(model='unsloth/gemma-3-4b-it-bnb-4bit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2533d154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SamplingParams Liste erstellt erfolgreich\n",
      "Anzahl SamplingParams: 2\n",
      "SamplingParams 0: structured_outputs type = <class 'vllm.sampling_params.StructuredOutputsParams'>\n",
      "SamplingParams 1: structured_outputs type = <class 'vllm.sampling_params.StructuredOutputsParams'>\n"
     ]
    }
   ],
   "source": [
    "# Beispiel für separate SamplingParams pro Prompt\n",
    "sampling_params_list = [\n",
    "    SamplingParams(\n",
    "        max_tokens=50, \n",
    "        temperature=0.7, \n",
    "        structured_outputs=StructuredOutputsParams(regex=r'RESTAURANT#GENERAL')\n",
    "    ),\n",
    "    SamplingParams(\n",
    "        max_tokens=50, \n",
    "        temperature=0.7, \n",
    "        structured_outputs=StructuredOutputsParams(regex=r'[1-9][0-9]\\.[0-9]{2}')\n",
    "    )\n",
    "]\n",
    "\n",
    "print('SamplingParams Liste erstellt erfolgreich')\n",
    "print(f'Anzahl SamplingParams: {len(sampling_params_list)}')\n",
    "for i, sp in enumerate(sampling_params_list):\n",
    "    print(f'SamplingParams {i}: structured_outputs type = {type(sp.structured_outputs)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c17f47f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding requests: 100%|██████████| 2/2 [00:00<00:00, 2418.16it/s]\n",
      "Processed prompts: 100%|██████████| 2/2 [00:00<00:00, 16.19it/s, est. speed input: 114.70 toks/s, output: 131.07 toks/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'RESTAURANT#GENERAL'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = llm.generate(\n",
    "    prompts=[\"Ciao, come stai?\", \"Qual è il significato della vita?\"],\n",
    "    sampling_params=sampling_params_list  # Liste mit 2 SamplingParams\n",
    ")\n",
    "outputs[0].outputs[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089e5f82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unsloth_training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
