{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509021e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBTASKS = [2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4439be12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from IPython.display import display\n",
    "from helper import *\n",
    "from evaluate import *\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7f8e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subtask2_train_split = get_performance_tabular(\n",
    "    \"cF1\", 2, strategy=\"train_split\")\n",
    "df_subtask3_train_split = get_performance_tabular(\n",
    "    \"cF1\", 3, strategy=\"train_split\")\n",
    "\n",
    "df_subtasks_train_split = {\n",
    "    3: df_subtask3_train_split,\n",
    "    2: df_subtask2_train_split\n",
    "}\n",
    "\n",
    "display(df_subtask2_train_split)\n",
    "display(df_subtask3_train_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3001ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_subtask2 = run_significance_tests(df_subtask2_train_split, 2)\n",
    "# results_subtask3 = run_significance_tests(df_subtask3_train_split, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3c54f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(format_table_parameter_tuning_for_latex(df_subtask2_train_split))\n",
    "display(format_table_parameter_tuning_for_latex(df_subtask3_train_split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3316cd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get df_subtask2_train_split values as 1d list\n",
    "# get df_subtask2_train_split values as 1d list (ohne Language und Domain)\n",
    "df_values_subtask2 = format_table_parameter_tuning_for_latex(df_subtask2_train_split).drop(columns=[\"Language\", \"Domain\"]).values.flatten().tolist()\n",
    "df_values_subtask3 = format_table_parameter_tuning_for_latex(df_subtask3_train_split).drop(columns=[\"Language\", \"Domain\"]).values.flatten().tolist()\n",
    "\n",
    "with open(os.path.join(\"plots\", \"parameter_optimization_subtask2.txt\"), \"w\") as f:\n",
    "    f.write(get_tabular_parameter_optimization(df_values_subtask2))\n",
    "\n",
    "with open(os.path.join(\"plots\", \"parameter_optimization_subtask3.txt\"), \"w\") as f:\n",
    "    f.write(get_tabular_parameter_optimization(df_values_subtask3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cf5abf",
   "metadata": {},
   "source": [
    "## Export Predictions in Valid Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e1b68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "STRATEGIES = [\"dev-train\"] #, \"test-train_dev\"]\n",
    "\n",
    "COLUMN_CONFIG = {\n",
    "    \"no_sc_no_guided_27b\": (\"unsloth/gemma-3-27b-it-bnb-4bit\", None, \"no_sc_no_guided\"),\n",
    "    \"sc_5_27b\": (\"unsloth/gemma-3-27b-it-bnb-4bit\", 5, \"sc_no_guided\"),\n",
    "    \"sc_10_27b\": (\"unsloth/gemma-3-27b-it-bnb-4bit\", 10, \"sc_no_guided\"),\n",
    "    \"sc_15_27b\": (\"unsloth/gemma-3-27b-it-bnb-4bit\", 15, \"sc_no_guided\"),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4627ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column_config in COLUMN_CONFIG.keys():\n",
    "  for strategy in STRATEGIES:\n",
    "    for subtask in SUBTASKS:\n",
    "        for language, domain in VALID_LANGUAGES_DOMAINS:\n",
    "            if True:\n",
    "                num_sc_bs = COLUMN_CONFIG[column_config][1]\n",
    "\n",
    "                predictions = get_performance(language, domain, subtask, strategy,\n",
    "                                              llm=f\"unsloth/gemma-3-27b-it-bnb-4bit\", num_preds_sc=num_sc_bs if num_sc_bs is not None else 5)[1][COLUMN_CONFIG[column_config][2]]\n",
    "                \n",
    "                output_dir = f\"exported_predictions/{strategy}/{column_config}/subtask_{subtask}/pred_{language}_{domain}.jsonl\"\n",
    "                os.makedirs(os.path.dirname(output_dir), exist_ok=True)\n",
    "                with open(output_dir, \"w\", encoding=\"utf-8\") as f:\n",
    "                    for pred in predictions:\n",
    "                        f.write(json.dumps(pred, ensure_ascii=False) + \"\\n\")\n",
    "            # except Exception as e:\n",
    "            #     print(\n",
    "            #         f\"Error processing Subtask {subtask} - Language: {language}, Domain: {domain}: {e}\")\n",
    "            #     continue\n",
    "            # print(\n",
    "            #     f\"Subtask {subtask} - Language: {language}, Domain: {domain} => Best Strategy: {strategy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7ab978",
   "metadata": {},
   "source": [
    "## Create Tables Dataset Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fc743f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ROWS = [\"train\", \"dev\", \"test\", \"test_cross_validation\"]\n",
    "DOMAIN_ORDER = [\"restaurant\", \"laptop\", \"hotel\"]  # Definiere die gewünschte Reihenfolge\n",
    "SUBTASK_ORDER = [2, 3]  # Erst Subtask 2, dann Subtask 3\n",
    "\n",
    "records_dataset_statistics = []\n",
    "\n",
    "for subtask in SUBTASKS:\n",
    "    for language, domain in VALID_LANGUAGES_DOMAINS:\n",
    "\n",
    "        # train + dev\n",
    "        for split in [\"train\", \"dev\"]:\n",
    "            count = len(get_dataset(subtask, language, domain, split=split))\n",
    "            records_dataset_statistics.append((split, domain, subtask, language, count))\n",
    "\n",
    "        # test (optional)\n",
    "        try:\n",
    "            count_test = len(get_dataset(subtask, language, domain, split=\"test\"))\n",
    "            records_dataset_statistics.append((\"test\", domain, subtask, language, count_test))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # test_cross_validation (als ganze Zahl)\n",
    "        train_size = len(get_dataset(subtask, language, domain, split=\"train\"))\n",
    "        records_dataset_statistics.append((\n",
    "            \"test_cross_validation\",\n",
    "            domain,\n",
    "            subtask,\n",
    "            language,\n",
    "            str(int(train_size * 0.2))\n",
    "        ))\n",
    "\n",
    "df_dataset_statistics = pd.DataFrame(\n",
    "    records_dataset_statistics,\n",
    "    columns=[\"split\", \"domain\", \"subtask\", \"language\", \"count\"]\n",
    ")\n",
    "\n",
    "# Konvertiere domain zu Categorical mit gewünschter Reihenfolge\n",
    "df_dataset_statistics[\"domain\"] = pd.Categorical(\n",
    "    df_dataset_statistics[\"domain\"], \n",
    "    categories=DOMAIN_ORDER, \n",
    "    ordered=True\n",
    ")\n",
    "\n",
    "df_dataset_statistics = (\n",
    "    df_dataset_statistics\n",
    "        .pivot(index=[\"split\", \"domain\"],\n",
    "               columns=[\"subtask\", \"language\"],\n",
    "               values=\"count\")\n",
    "        .sort_index(level=[\"split\", \"domain\"], key=lambda x: x.map({s: i for i, s in enumerate(ROWS)} if x.name == \"split\" else {d: i for i, d in enumerate(DOMAIN_ORDER)}))\n",
    ")\n",
    "\n",
    "# Spalten nach gewünschter Subtask-Reihenfolge sortieren (erst 2, dann 3)\n",
    "df_dataset_statistics = df_dataset_statistics.reindex(\n",
    "    columns=sorted(df_dataset_statistics.columns, key=lambda x: (SUBTASK_ORDER.index(x[0]), x[1]))\n",
    ")\n",
    "\n",
    "df_dataset_statistics = df_dataset_statistics.applymap(\n",
    "    lambda x: f\"{int(x):,}\" if pd.notna(x) else \"-\"\n",
    ")\n",
    "\n",
    "# get values from left to right from top to bottom as 1D list\n",
    "values_list_dataset_statistics = df_dataset_statistics.values.flatten().tolist()\n",
    "df_dataset_statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9ab0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"plots/muster/dataset.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    dataset_muster = f.read()\n",
    "\n",
    "# gehe von xxxx zu xxxx und trage die Werte ein\n",
    "for value in values_list_dataset_statistics:\n",
    "    dataset_muster = dataset_muster.replace(\"xxxx\", value, 1)\n",
    "\n",
    "with open(\"plots/dataset_statistics.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(dataset_muster)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_nils_hellwig",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
