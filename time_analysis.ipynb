{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cec17db",
   "metadata": {},
   "outputs": [],
   "source": [
    "EVALUATION_SET = \"test\"  # Kann später auf \"test\" gewechselt werden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc983d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subtask 2:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>domain</th>\n",
       "      <th>num_examples_train</th>\n",
       "      <th>num_seconds_train</th>\n",
       "      <th>avg_seconds_train_per_1000</th>\n",
       "      <th>num_examples_evaluate</th>\n",
       "      <th>num_seconds_evaluate_sc</th>\n",
       "      <th>num_seconds_evaluate_per_100_sc</th>\n",
       "      <th>num_seconds_evaluate_no_sc</th>\n",
       "      <th>num_seconds_evaluate_per_100_no_sc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eng</td>\n",
       "      <td>restaurant</td>\n",
       "      <td>2,284</td>\n",
       "      <td>3,860</td>\n",
       "      <td>1,690</td>\n",
       "      <td>1,000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eng</td>\n",
       "      <td>laptop</td>\n",
       "      <td>4,076</td>\n",
       "      <td>6,515</td>\n",
       "      <td>1,598</td>\n",
       "      <td>1,000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jpn</td>\n",
       "      <td>hotel</td>\n",
       "      <td>1,600</td>\n",
       "      <td>3,415</td>\n",
       "      <td>2,134</td>\n",
       "      <td>800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rus</td>\n",
       "      <td>restaurant</td>\n",
       "      <td>1,240</td>\n",
       "      <td>2,638</td>\n",
       "      <td>2,127</td>\n",
       "      <td>630</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tat</td>\n",
       "      <td>restaurant</td>\n",
       "      <td>1,240</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>630</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ukr</td>\n",
       "      <td>restaurant</td>\n",
       "      <td>1,240</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>630</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>zho</td>\n",
       "      <td>restaurant</td>\n",
       "      <td>6,050</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1,000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>zho</td>\n",
       "      <td>laptop</td>\n",
       "      <td>3,490</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1,000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>average</td>\n",
       "      <td></td>\n",
       "      <td>2,652</td>\n",
       "      <td>2,053</td>\n",
       "      <td>943</td>\n",
       "      <td>836</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  language      domain num_examples_train num_seconds_train  \\\n",
       "0      eng  restaurant              2,284             3,860   \n",
       "1      eng      laptop              4,076             6,515   \n",
       "2      jpn       hotel              1,600             3,415   \n",
       "3      rus  restaurant              1,240             2,638   \n",
       "4      tat  restaurant              1,240                 0   \n",
       "5      ukr  restaurant              1,240                 0   \n",
       "6      zho  restaurant              6,050                 0   \n",
       "7      zho      laptop              3,490                 0   \n",
       "8  average                          2,652             2,053   \n",
       "\n",
       "  avg_seconds_train_per_1000 num_examples_evaluate num_seconds_evaluate_sc  \\\n",
       "0                      1,690                 1,000                       0   \n",
       "1                      1,598                 1,000                       0   \n",
       "2                      2,134                   800                       0   \n",
       "3                      2,127                   630                       0   \n",
       "4                          0                   630                       0   \n",
       "5                          0                   630                       0   \n",
       "6                          0                 1,000                       0   \n",
       "7                          0                 1,000                       0   \n",
       "8                        943                   836                       0   \n",
       "\n",
       "  num_seconds_evaluate_per_100_sc num_seconds_evaluate_no_sc  \\\n",
       "0                               0                          0   \n",
       "1                               0                          0   \n",
       "2                               0                          0   \n",
       "3                               0                          0   \n",
       "4                               0                          0   \n",
       "5                               0                          0   \n",
       "6                               0                          0   \n",
       "7                               0                          0   \n",
       "8                               0                          0   \n",
       "\n",
       "  num_seconds_evaluate_per_100_no_sc  \n",
       "0                                  0  \n",
       "1                                  0  \n",
       "2                                  0  \n",
       "3                                  0  \n",
       "4                                  0  \n",
       "5                                  0  \n",
       "6                                  0  \n",
       "7                                  0  \n",
       "8                                  0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Subtask 3:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>domain</th>\n",
       "      <th>num_examples_train</th>\n",
       "      <th>num_seconds_train</th>\n",
       "      <th>avg_seconds_train_per_1000</th>\n",
       "      <th>num_examples_evaluate</th>\n",
       "      <th>num_seconds_evaluate_sc</th>\n",
       "      <th>num_seconds_evaluate_per_100_sc</th>\n",
       "      <th>num_seconds_evaluate_no_sc</th>\n",
       "      <th>num_seconds_evaluate_per_100_no_sc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eng</td>\n",
       "      <td>restaurant</td>\n",
       "      <td>2,284</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1,000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eng</td>\n",
       "      <td>laptop</td>\n",
       "      <td>4,076</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1,000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jpn</td>\n",
       "      <td>hotel</td>\n",
       "      <td>1,600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rus</td>\n",
       "      <td>restaurant</td>\n",
       "      <td>1,240</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>630</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tat</td>\n",
       "      <td>restaurant</td>\n",
       "      <td>1,240</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>630</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ukr</td>\n",
       "      <td>restaurant</td>\n",
       "      <td>1,240</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>630</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>zho</td>\n",
       "      <td>restaurant</td>\n",
       "      <td>6,050</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1,000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>zho</td>\n",
       "      <td>laptop</td>\n",
       "      <td>3,490</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1,000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>average</td>\n",
       "      <td></td>\n",
       "      <td>2,652</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>836</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  language      domain num_examples_train num_seconds_train  \\\n",
       "0      eng  restaurant              2,284                 0   \n",
       "1      eng      laptop              4,076                 0   \n",
       "2      jpn       hotel              1,600                 0   \n",
       "3      rus  restaurant              1,240                 0   \n",
       "4      tat  restaurant              1,240                 0   \n",
       "5      ukr  restaurant              1,240                 0   \n",
       "6      zho  restaurant              6,050                 0   \n",
       "7      zho      laptop              3,490                 0   \n",
       "8  average                          2,652                 0   \n",
       "\n",
       "  avg_seconds_train_per_1000 num_examples_evaluate num_seconds_evaluate_sc  \\\n",
       "0                          0                 1,000                       0   \n",
       "1                          0                 1,000                       0   \n",
       "2                          0                   800                       0   \n",
       "3                          0                   630                       0   \n",
       "4                          0                   630                       0   \n",
       "5                          0                   630                       0   \n",
       "6                          0                 1,000                       0   \n",
       "7                          0                 1,000                       0   \n",
       "8                          0                   836                       0   \n",
       "\n",
       "  num_seconds_evaluate_per_100_sc num_seconds_evaluate_no_sc  \\\n",
       "0                               0                          0   \n",
       "1                               0                          0   \n",
       "2                               0                          0   \n",
       "3                               0                          0   \n",
       "4                               0                          0   \n",
       "5                               0                          0   \n",
       "6                               0                          0   \n",
       "7                               0                          0   \n",
       "8                               0                          0   \n",
       "\n",
       "  num_seconds_evaluate_per_100_no_sc  \n",
       "0                                  0  \n",
       "1                                  0  \n",
       "2                                  0  \n",
       "3                                  0  \n",
       "4                                  0  \n",
       "5                                  0  \n",
       "6                                  0  \n",
       "7                                  0  \n",
       "8                                  0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load time_logs.jsonl having lines like this:\n",
    "# {\"subtask\": 3, \"language\": \"tat\", \"domain\": \"restaurant\", \"seed_run\": 0, \"strategy\": \"train_split\", \"split_idx\": 2, \"model_name_or_path\": \"unsloth/gemma-3-27b-it-bnb-4bit\", \"evaluation_time\": 151.838674, \"timestamp\": \"2025-12-11T06:25:19.184137\", \"self_consistency\": true, \"guided\": false}\n",
    "\n",
    "# Lade time_logs.jsonl\n",
    "\n",
    "log_eval_data = \"test-train_dev\"\n",
    "\n",
    "import json\n",
    "from helper import *\n",
    "import pandas as pd\n",
    "\n",
    "with open(\"time_logs.jsonl\", \"r\") as f:\n",
    "    time_logs = [json.loads(line) for line in f.readlines()]\n",
    "\n",
    "evaluation_times = [\n",
    "    log for log in time_logs\n",
    "    if log.get(\"strategy\") == log_eval_data and \"training_time\" in log and log.get(\"model_name_or_path\") == \"unsloth/gemma-3-27b-it-bnb-4bit\"\n",
    "]\n",
    "\n",
    "# Neue Filter für evaluation_time - self_consistency True\n",
    "evaluation_logs_sc = [\n",
    "    log for log in time_logs\n",
    "    if log.get(\"strategy\") == log_eval_data and log.get(\"model_name_or_path\") == \"unsloth/gemma-3-27b-it-bnb-4bit\" and log.get(\"self_consistency\") == True and log.get(\"guided\") == False\n",
    "]\n",
    "\n",
    "# Neue Filter für evaluation_time - self_consistency False\n",
    "evaluation_logs_no_sc = [\n",
    "    log for log in time_logs\n",
    "    if log.get(\"strategy\") == log_eval_data and log.get(\"model_name_or_path\") == \"unsloth/gemma-3-27b-it-bnb-4bit\" and log.get(\"self_consistency\") == False and log.get(\"guided\") == False\n",
    "]\n",
    "\n",
    "\n",
    "VALID_LANGUAGES_DOMAINS = [\n",
    "    (\"eng\", \"restaurant\"),\n",
    "    (\"eng\", \"laptop\"),\n",
    "    (\"jpn\", \"hotel\"),\n",
    "    (\"rus\", \"restaurant\"),\n",
    "    (\"tat\", \"restaurant\"),\n",
    "    (\"ukr\", \"restaurant\"),\n",
    "    (\"zho\", \"restaurant\"),\n",
    "    (\"zho\", \"laptop\"),\n",
    "]\n",
    "\n",
    "# count all combinations of subtask, language, domain in evaluation_times\n",
    "records_evaluation_times = []\n",
    "for subtask in [2, 3]:\n",
    "    for language, domain in VALID_LANGUAGES_DOMAINS:\n",
    "        filtered_logs = [\n",
    "            log for log in evaluation_times\n",
    "            if log[\"subtask\"] == subtask and log[\"language\"] == language and log[\"domain\"] == domain\n",
    "        ]\n",
    "        total_time = sum(log[\"training_time\"] for log in filtered_logs)\n",
    "        records_evaluation_times.append((subtask, language, domain, total_time))\n",
    "        \n",
    "# add number of evaluation examples (train for training, dev for evaluation)\n",
    "for i, (subtask, language, domain, total_time) in enumerate(records_evaluation_times):\n",
    "    num_examples_train = len(get_dataset(subtask, language, domain, split=\"train\"))\n",
    "    num_examples_dev = len(get_dataset(subtask, language, domain, split=EVALUATION_SET))\n",
    "    records_evaluation_times[i] = (subtask, language, domain, total_time, num_examples_train, num_examples_dev)\n",
    "    \n",
    "# calculate average time per 1000 examples\n",
    "for i, (subtask, language, domain, total_time, num_examples_train, num_examples_dev) in enumerate(records_evaluation_times):\n",
    "    avg_time_per_1000 = (total_time / num_examples_train) * 1000 if num_examples_train > 0 else 0\n",
    "    records_evaluation_times[i] = (subtask, language, domain, total_time, num_examples_train, num_examples_dev, avg_time_per_1000)\n",
    "    \n",
    "# Berechne average evaluation_time für sc und no_sc\n",
    "for i, (subtask, language, domain, total_time, num_examples_train, num_examples_dev, avg_time_per_1000) in enumerate(records_evaluation_times):\n",
    "    # Self Consistency True\n",
    "    filtered_eval_logs_sc = [\n",
    "        log for log in evaluation_logs_sc\n",
    "        if log[\"subtask\"] == subtask and log[\"language\"] == language and log[\"domain\"] == domain\n",
    "    ]\n",
    "    eval_times_sc = [log[\"evaluation_time\"] for log in filtered_eval_logs_sc if \"evaluation_time\" in log]\n",
    "    avg_evaluation_time_sc = sum(eval_times_sc) / len(eval_times_sc) if eval_times_sc else 0\n",
    "    avg_evaluation_time_per_100_sc = (avg_evaluation_time_sc / num_examples_dev) * 100 if num_examples_dev > 0 else 0\n",
    "    \n",
    "    # Self Consistency False\n",
    "    filtered_eval_logs_no_sc = [\n",
    "        log for log in evaluation_logs_no_sc\n",
    "        if log[\"subtask\"] == subtask and log[\"language\"] == language and log[\"domain\"] == domain\n",
    "    ]\n",
    "    eval_times_no_sc = [log[\"evaluation_time\"] for log in filtered_eval_logs_no_sc if \"evaluation_time\" in log]\n",
    "    avg_evaluation_time_no_sc = sum(eval_times_no_sc) / len(eval_times_no_sc) if eval_times_no_sc else 0\n",
    "    avg_evaluation_time_per_100_no_sc = (avg_evaluation_time_no_sc / num_examples_dev) * 100 if num_examples_dev > 0 else 0\n",
    "    \n",
    "    records_evaluation_times[i] = (subtask, language, domain, total_time, num_examples_train, num_examples_dev, avg_time_per_1000, \n",
    "                                   avg_evaluation_time_sc, avg_evaluation_time_per_100_sc,\n",
    "                                   avg_evaluation_time_no_sc, avg_evaluation_time_per_100_no_sc)\n",
    "    \n",
    "# convert records_evaluation_times to pandas dataframe\n",
    "df_evaluation_times = pd.DataFrame(\n",
    "    records_evaluation_times,\n",
    "    columns=[\"subtask\", \"language\", \"domain\", \"total_time\", \"num_examples_train\", \"num_examples_dev\", \"avg_time_per_1000\", \n",
    "             \"avg_evaluation_time_sc\", \"avg_evaluation_time_per_100_sc\",\n",
    "             \"avg_evaluation_time_no_sc\", \"avg_evaluation_time_per_100_no_sc\"]\n",
    ")   \n",
    "\n",
    "# Erstelle separate DataFrames für jeden Subtask\n",
    "df_evaluation_times_subtask2 = df_evaluation_times[df_evaluation_times[\"subtask\"] == 2].copy()\n",
    "df_evaluation_times_subtask3 = df_evaluation_times[df_evaluation_times[\"subtask\"] == 3].copy()\n",
    "\n",
    "# Funktion zum Hinzufügen der Average-Zeile\n",
    "def add_average_row(df):\n",
    "    avg_row = df.select_dtypes(include=[float, int]).mean()\n",
    "    avg_row[\"language\"] = \"average\"\n",
    "    avg_row[\"domain\"] = \"\"\n",
    "    avg_row[\"subtask\"] = df[\"subtask\"].iloc[0]\n",
    "    avg_df = pd.DataFrame([avg_row])\n",
    "    return pd.concat([df, avg_df], ignore_index=True)\n",
    "\n",
    "# Füge Average-Zeile hinzu\n",
    "df_evaluation_times_subtask2 = add_average_row(df_evaluation_times_subtask2)\n",
    "df_evaluation_times_subtask3 = add_average_row(df_evaluation_times_subtask3)\n",
    "\n",
    "# Formatiere die Zeiten als Ganzzahlen mit \",\" als Tausendertrennzeichen\n",
    "for df in [df_evaluation_times_subtask2, df_evaluation_times_subtask3]:\n",
    "    df[\"total_time\"] = df[\"total_time\"].apply(lambda x: f\"{int(x):,}\" if pd.notna(x) else \"-\")\n",
    "    df[\"avg_time_per_1000\"] = df[\"avg_time_per_1000\"].apply(lambda x: f\"{int(x):,}\" if pd.notna(x) else \"-\")\n",
    "    df[\"num_examples_train\"] = df[\"num_examples_train\"].apply(lambda x: f\"{int(x):,}\" if pd.notna(x) else \"-\")\n",
    "    df[\"num_examples_dev\"] = df[\"num_examples_dev\"].apply(lambda x: f\"{int(x):,}\" if pd.notna(x) else \"-\")\n",
    "    df[\"avg_evaluation_time_sc\"] = df[\"avg_evaluation_time_sc\"].apply(lambda x: f\"{int(x):,}\" if pd.notna(x) else \"-\")\n",
    "    df[\"avg_evaluation_time_per_100_sc\"] = df[\"avg_evaluation_time_per_100_sc\"].apply(lambda x: f\"{int(x):,}\" if pd.notna(x) else \"-\")\n",
    "    df[\"avg_evaluation_time_no_sc\"] = df[\"avg_evaluation_time_no_sc\"].apply(lambda x: f\"{int(x):,}\" if pd.notna(x) else \"-\")\n",
    "    df[\"avg_evaluation_time_per_100_no_sc\"] = df[\"avg_evaluation_time_per_100_no_sc\"].apply(lambda x: f\"{int(x):,}\" if pd.notna(x) else \"-\")\n",
    "\n",
    "# Benenne Spalten um\n",
    "for df in [df_evaluation_times_subtask2, df_evaluation_times_subtask3]:\n",
    "    df.rename(columns={\n",
    "        \"total_time\": \"num_seconds_train\",\n",
    "        \"avg_time_per_1000\": \"avg_seconds_train_per_1000\",\n",
    "        \"num_examples_dev\": \"num_examples_evaluate\",\n",
    "        \"avg_evaluation_time_sc\": \"num_seconds_evaluate_sc\",\n",
    "        \"avg_evaluation_time_per_100_sc\": \"num_seconds_evaluate_per_100_sc\",\n",
    "        \"avg_evaluation_time_no_sc\": \"num_seconds_evaluate_no_sc\",\n",
    "        \"avg_evaluation_time_per_100_no_sc\": \"num_seconds_evaluate_per_100_no_sc\"\n",
    "    }, inplace=True)\n",
    "\n",
    "# Ordne Spalten in gewünschter Reihenfolge\n",
    "column_order = [\n",
    "    \"language\",\n",
    "    \"domain\",\n",
    "    \"num_examples_train\",\n",
    "    \"num_seconds_train\",\n",
    "    \"avg_seconds_train_per_1000\",\n",
    "    \"num_examples_evaluate\",\n",
    "    \"num_seconds_evaluate_sc\",\n",
    "    \"num_seconds_evaluate_per_100_sc\",\n",
    "    \"num_seconds_evaluate_no_sc\",\n",
    "    \"num_seconds_evaluate_per_100_no_sc\"\n",
    "]\n",
    "\n",
    "df_evaluation_times_subtask2 = df_evaluation_times_subtask2[column_order]\n",
    "df_evaluation_times_subtask3 = df_evaluation_times_subtask3[column_order]\n",
    "\n",
    "# Zeige die DataFrames an ohne Index\n",
    "from IPython.display import display\n",
    "\n",
    "print(\"Subtask 2:\")\n",
    "display(df_evaluation_times_subtask2)\n",
    "\n",
    "print(\"\\nSubtask 3:\")\n",
    "display(df_evaluation_times_subtask3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4330f6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert eng to English, zho to Chinese, jpn to Japanese, rus to Russian, tat to Tatar, ukr to Ukrainian in both dataframes\n",
    "language_map = {\n",
    "    \"eng\": \"English\",\n",
    "    \"zho\": \"Chinese\",\n",
    "    \"jpn\": \"Japanese\",\n",
    "    \"rus\": \"Russian\",\n",
    "    \"tat\": \"Tatar\",\n",
    "    \"ukr\": \"Ukrainian\",\n",
    "    \"average\": \"Average\"\n",
    "}\n",
    "df_evaluation_times_subtask2.loc[:, \"language\"] = df_evaluation_times_subtask2[\"language\"].map(language_map)\n",
    "df_evaluation_times_subtask3.loc[:, \"language\"] = df_evaluation_times_subtask3[\"language\"].map(language_map)\n",
    "# uppercase first letter of domain in both dataframes\n",
    "df_evaluation_times_subtask2.loc[:, \"domain\"] = df_evaluation_times_subtask2[\"domain\"].str.capitalize()\n",
    "df_evaluation_times_subtask3.loc[:, \"domain\"] = df_evaluation_times_subtask3[\"domain\"].str.capitalize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "617f6702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load \"plots/muster/time.txt\" as text\n",
    "with open(\"plots/muster/time.txt\", \"r\") as f:\n",
    "    time_txt = f.read()\n",
    "\n",
    "# insert the values from df_evaluation_times_subtask2 and df_evaluation_times_subtask3 into time_txt\n",
    "# go from xxxx to xxxx and replace\n",
    "subtask_3_time_list = df_evaluation_times_subtask3.values.flatten().tolist()\n",
    "subtask_2_time_list = df_evaluation_times_subtask2.values.flatten().tolist()\n",
    "\n",
    "time_txt_2 = time_txt\n",
    "\n",
    "for value in subtask_2_time_list:\n",
    "    if value == \"Average\":\n",
    "        continue\n",
    "    time_txt_2 = time_txt_2.replace(\"xxxx\", str(value), 1)\n",
    "    \n",
    "time_txt_3 = time_txt\n",
    "\n",
    "for value in subtask_3_time_list:\n",
    "    if value == \"Average\":\n",
    "        continue\n",
    "    time_txt_3 = time_txt_3.replace(\"xxxx\", str(value), 1)\n",
    "\n",
    "with open(\"plots/time_subtask2.txt\", \"w\") as f:\n",
    "    f.write(time_txt_2)\n",
    "\n",
    "with open(\"plots/time_subtask3.txt\", \"w\") as f:\n",
    "    f.write(time_txt_3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unsloth_training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
