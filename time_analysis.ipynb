{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cec17db",
   "metadata": {},
   "outputs": [],
   "source": [
    "EVALUATION_SET = \"test\"  # Kann später auf \"test\" gewechselt werden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc983d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subtask 2:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>domain</th>\n",
       "      <th>num_examples_train</th>\n",
       "      <th>num_seconds_train</th>\n",
       "      <th>avg_seconds_train_per_1000</th>\n",
       "      <th>num_examples_evaluate</th>\n",
       "      <th>num_seconds_evaluate_sc</th>\n",
       "      <th>num_seconds_evaluate_per_example_sc</th>\n",
       "      <th>num_seconds_evaluate_no_sc</th>\n",
       "      <th>num_seconds_evaluate_per_example_no_sc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eng</td>\n",
       "      <td>restaurant</td>\n",
       "      <td>2,284</td>\n",
       "      <td>3,860</td>\n",
       "      <td>1,690</td>\n",
       "      <td>1,000</td>\n",
       "      <td>322</td>\n",
       "      <td>0.322</td>\n",
       "      <td>34</td>\n",
       "      <td>0.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eng</td>\n",
       "      <td>laptop</td>\n",
       "      <td>4,076</td>\n",
       "      <td>6,515</td>\n",
       "      <td>1,598</td>\n",
       "      <td>1,000</td>\n",
       "      <td>282</td>\n",
       "      <td>0.283</td>\n",
       "      <td>29</td>\n",
       "      <td>0.029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jpn</td>\n",
       "      <td>hotel</td>\n",
       "      <td>1,600</td>\n",
       "      <td>3,415</td>\n",
       "      <td>2,134</td>\n",
       "      <td>800</td>\n",
       "      <td>232</td>\n",
       "      <td>0.291</td>\n",
       "      <td>25</td>\n",
       "      <td>0.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rus</td>\n",
       "      <td>restaurant</td>\n",
       "      <td>1,240</td>\n",
       "      <td>2,638</td>\n",
       "      <td>2,127</td>\n",
       "      <td>630</td>\n",
       "      <td>276</td>\n",
       "      <td>0.439</td>\n",
       "      <td>34</td>\n",
       "      <td>0.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tat</td>\n",
       "      <td>restaurant</td>\n",
       "      <td>1,240</td>\n",
       "      <td>3,686</td>\n",
       "      <td>2,972</td>\n",
       "      <td>630</td>\n",
       "      <td>300</td>\n",
       "      <td>0.477</td>\n",
       "      <td>39</td>\n",
       "      <td>0.063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ukr</td>\n",
       "      <td>restaurant</td>\n",
       "      <td>1,240</td>\n",
       "      <td>2,935</td>\n",
       "      <td>2,367</td>\n",
       "      <td>630</td>\n",
       "      <td>297</td>\n",
       "      <td>0.471</td>\n",
       "      <td>41</td>\n",
       "      <td>0.066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>zho</td>\n",
       "      <td>restaurant</td>\n",
       "      <td>6,050</td>\n",
       "      <td>10,281</td>\n",
       "      <td>1,699</td>\n",
       "      <td>1,000</td>\n",
       "      <td>517</td>\n",
       "      <td>0.518</td>\n",
       "      <td>50</td>\n",
       "      <td>0.051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>zho</td>\n",
       "      <td>laptop</td>\n",
       "      <td>3,490</td>\n",
       "      <td>7,143</td>\n",
       "      <td>2,046</td>\n",
       "      <td>1,000</td>\n",
       "      <td>352</td>\n",
       "      <td>0.353</td>\n",
       "      <td>41</td>\n",
       "      <td>0.041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>average</td>\n",
       "      <td></td>\n",
       "      <td>2,652</td>\n",
       "      <td>5,059</td>\n",
       "      <td>2,079</td>\n",
       "      <td>836</td>\n",
       "      <td>322</td>\n",
       "      <td>0.394</td>\n",
       "      <td>37</td>\n",
       "      <td>0.047</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  language      domain num_examples_train num_seconds_train  \\\n",
       "0      eng  restaurant              2,284             3,860   \n",
       "1      eng      laptop              4,076             6,515   \n",
       "2      jpn       hotel              1,600             3,415   \n",
       "3      rus  restaurant              1,240             2,638   \n",
       "4      tat  restaurant              1,240             3,686   \n",
       "5      ukr  restaurant              1,240             2,935   \n",
       "6      zho  restaurant              6,050            10,281   \n",
       "7      zho      laptop              3,490             7,143   \n",
       "8  average                          2,652             5,059   \n",
       "\n",
       "  avg_seconds_train_per_1000 num_examples_evaluate num_seconds_evaluate_sc  \\\n",
       "0                      1,690                 1,000                     322   \n",
       "1                      1,598                 1,000                     282   \n",
       "2                      2,134                   800                     232   \n",
       "3                      2,127                   630                     276   \n",
       "4                      2,972                   630                     300   \n",
       "5                      2,367                   630                     297   \n",
       "6                      1,699                 1,000                     517   \n",
       "7                      2,046                 1,000                     352   \n",
       "8                      2,079                   836                     322   \n",
       "\n",
       "  num_seconds_evaluate_per_example_sc num_seconds_evaluate_no_sc  \\\n",
       "0                               0.322                         34   \n",
       "1                               0.283                         29   \n",
       "2                               0.291                         25   \n",
       "3                               0.439                         34   \n",
       "4                               0.477                         39   \n",
       "5                               0.471                         41   \n",
       "6                               0.518                         50   \n",
       "7                               0.353                         41   \n",
       "8                               0.394                         37   \n",
       "\n",
       "  num_seconds_evaluate_per_example_no_sc  \n",
       "0                                  0.035  \n",
       "1                                  0.029  \n",
       "2                                  0.032  \n",
       "3                                  0.055  \n",
       "4                                  0.063  \n",
       "5                                  0.066  \n",
       "6                                  0.051  \n",
       "7                                  0.041  \n",
       "8                                  0.047  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Subtask 3:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>domain</th>\n",
       "      <th>num_examples_train</th>\n",
       "      <th>num_seconds_train</th>\n",
       "      <th>avg_seconds_train_per_1000</th>\n",
       "      <th>num_examples_evaluate</th>\n",
       "      <th>num_seconds_evaluate_sc</th>\n",
       "      <th>num_seconds_evaluate_per_example_sc</th>\n",
       "      <th>num_seconds_evaluate_no_sc</th>\n",
       "      <th>num_seconds_evaluate_per_example_no_sc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eng</td>\n",
       "      <td>restaurant</td>\n",
       "      <td>2,284</td>\n",
       "      <td>4,957</td>\n",
       "      <td>2,170</td>\n",
       "      <td>1,000</td>\n",
       "      <td>400</td>\n",
       "      <td>0.401</td>\n",
       "      <td>41</td>\n",
       "      <td>0.041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eng</td>\n",
       "      <td>laptop</td>\n",
       "      <td>4,076</td>\n",
       "      <td>9,678</td>\n",
       "      <td>2,374</td>\n",
       "      <td>1,000</td>\n",
       "      <td>391</td>\n",
       "      <td>0.392</td>\n",
       "      <td>41</td>\n",
       "      <td>0.041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jpn</td>\n",
       "      <td>hotel</td>\n",
       "      <td>1,600</td>\n",
       "      <td>4,496</td>\n",
       "      <td>2,810</td>\n",
       "      <td>800</td>\n",
       "      <td>318</td>\n",
       "      <td>0.398</td>\n",
       "      <td>36</td>\n",
       "      <td>0.045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rus</td>\n",
       "      <td>restaurant</td>\n",
       "      <td>1,240</td>\n",
       "      <td>3,266</td>\n",
       "      <td>2,633</td>\n",
       "      <td>630</td>\n",
       "      <td>315</td>\n",
       "      <td>0.500</td>\n",
       "      <td>44</td>\n",
       "      <td>0.070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tat</td>\n",
       "      <td>restaurant</td>\n",
       "      <td>1,240</td>\n",
       "      <td>4,489</td>\n",
       "      <td>3,620</td>\n",
       "      <td>630</td>\n",
       "      <td>344</td>\n",
       "      <td>0.547</td>\n",
       "      <td>46</td>\n",
       "      <td>0.074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ukr</td>\n",
       "      <td>restaurant</td>\n",
       "      <td>1,240</td>\n",
       "      <td>3,636</td>\n",
       "      <td>2,932</td>\n",
       "      <td>630</td>\n",
       "      <td>358</td>\n",
       "      <td>0.568</td>\n",
       "      <td>43</td>\n",
       "      <td>0.069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>zho</td>\n",
       "      <td>restaurant</td>\n",
       "      <td>6,050</td>\n",
       "      <td>12,829</td>\n",
       "      <td>2,120</td>\n",
       "      <td>1,000</td>\n",
       "      <td>685</td>\n",
       "      <td>0.686</td>\n",
       "      <td>60</td>\n",
       "      <td>0.060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>zho</td>\n",
       "      <td>laptop</td>\n",
       "      <td>3,490</td>\n",
       "      <td>10,066</td>\n",
       "      <td>2,884</td>\n",
       "      <td>1,000</td>\n",
       "      <td>469</td>\n",
       "      <td>0.470</td>\n",
       "      <td>51</td>\n",
       "      <td>0.052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>average</td>\n",
       "      <td></td>\n",
       "      <td>2,652</td>\n",
       "      <td>6,677</td>\n",
       "      <td>2,693</td>\n",
       "      <td>836</td>\n",
       "      <td>410</td>\n",
       "      <td>0.495</td>\n",
       "      <td>45</td>\n",
       "      <td>0.057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  language      domain num_examples_train num_seconds_train  \\\n",
       "0      eng  restaurant              2,284             4,957   \n",
       "1      eng      laptop              4,076             9,678   \n",
       "2      jpn       hotel              1,600             4,496   \n",
       "3      rus  restaurant              1,240             3,266   \n",
       "4      tat  restaurant              1,240             4,489   \n",
       "5      ukr  restaurant              1,240             3,636   \n",
       "6      zho  restaurant              6,050            12,829   \n",
       "7      zho      laptop              3,490            10,066   \n",
       "8  average                          2,652             6,677   \n",
       "\n",
       "  avg_seconds_train_per_1000 num_examples_evaluate num_seconds_evaluate_sc  \\\n",
       "0                      2,170                 1,000                     400   \n",
       "1                      2,374                 1,000                     391   \n",
       "2                      2,810                   800                     318   \n",
       "3                      2,633                   630                     315   \n",
       "4                      3,620                   630                     344   \n",
       "5                      2,932                   630                     358   \n",
       "6                      2,120                 1,000                     685   \n",
       "7                      2,884                 1,000                     469   \n",
       "8                      2,693                   836                     410   \n",
       "\n",
       "  num_seconds_evaluate_per_example_sc num_seconds_evaluate_no_sc  \\\n",
       "0                               0.401                         41   \n",
       "1                               0.392                         41   \n",
       "2                               0.398                         36   \n",
       "3                               0.500                         44   \n",
       "4                               0.547                         46   \n",
       "5                               0.568                         43   \n",
       "6                               0.686                         60   \n",
       "7                               0.470                         51   \n",
       "8                               0.495                         45   \n",
       "\n",
       "  num_seconds_evaluate_per_example_no_sc  \n",
       "0                                  0.041  \n",
       "1                                  0.041  \n",
       "2                                  0.045  \n",
       "3                                  0.070  \n",
       "4                                  0.074  \n",
       "5                                  0.069  \n",
       "6                                  0.060  \n",
       "7                                  0.052  \n",
       "8                                  0.057  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load time_logs.jsonl having lines like this:\n",
    "# {\"subtask\": 3, \"language\": \"tat\", \"domain\": \"restaurant\", \"seed_run\": 0, \"strategy\": \"train_split\", \"split_idx\": 2, \"model_name_or_path\": \"unsloth/gemma-3-27b-it-bnb-4bit\", \"evaluation_time\": 151.838674, \"timestamp\": \"2025-12-11T06:25:19.184137\", \"self_consistency\": true, \"guided\": false}\n",
    "\n",
    "# Lade time_logs.jsonl\n",
    "\n",
    "log_eval_data = \"test-train_dev\"\n",
    "\n",
    "import json\n",
    "from helper import *\n",
    "import pandas as pd\n",
    "\n",
    "with open(\"time_logs.jsonl\", \"r\") as f:\n",
    "    time_logs = [json.loads(line) for line in f.readlines()]\n",
    "\n",
    "evaluation_times = [\n",
    "    log for log in time_logs\n",
    "    if log.get(\"strategy\") == log_eval_data and \"training_time\" in log and log.get(\"model_name_or_path\") == \"unsloth/gemma-3-27b-it-bnb-4bit\"\n",
    "]\n",
    "\n",
    "# Neue Filter für evaluation_time - self_consistency True\n",
    "evaluation_logs_sc = [\n",
    "    log for log in time_logs\n",
    "    if log.get(\"strategy\") == log_eval_data and log.get(\"model_name_or_path\") == \"unsloth/gemma-3-27b-it-bnb-4bit\" and log.get(\"self_consistency\") == True and log.get(\"guided\") == False\n",
    "]\n",
    "\n",
    "# Neue Filter für evaluation_time - self_consistency False\n",
    "evaluation_logs_no_sc = [\n",
    "    log for log in time_logs\n",
    "    if log.get(\"strategy\") == log_eval_data and log.get(\"model_name_or_path\") == \"unsloth/gemma-3-27b-it-bnb-4bit\" and log.get(\"self_consistency\") == False and log.get(\"guided\") == False\n",
    "]\n",
    "\n",
    "\n",
    "VALID_LANGUAGES_DOMAINS = [\n",
    "    (\"eng\", \"restaurant\"),\n",
    "    (\"eng\", \"laptop\"),\n",
    "    (\"jpn\", \"hotel\"),\n",
    "    (\"rus\", \"restaurant\"),\n",
    "    (\"tat\", \"restaurant\"),\n",
    "    (\"ukr\", \"restaurant\"),\n",
    "    (\"zho\", \"restaurant\"),\n",
    "    (\"zho\", \"laptop\"),\n",
    "]\n",
    "\n",
    "# count all combinations of subtask, language, domain in evaluation_times\n",
    "records_evaluation_times = []\n",
    "for subtask in [2, 3]:\n",
    "    for language, domain in VALID_LANGUAGES_DOMAINS:\n",
    "        filtered_logs = [\n",
    "            log for log in evaluation_times\n",
    "            if log[\"subtask\"] == subtask and log[\"language\"] == language and log[\"domain\"] == domain\n",
    "        ]\n",
    "        total_time = sum(log[\"training_time\"] for log in filtered_logs)\n",
    "        records_evaluation_times.append((subtask, language, domain, total_time))\n",
    "        \n",
    "# add number of evaluation examples (train for training, dev for evaluation)\n",
    "for i, (subtask, language, domain, total_time) in enumerate(records_evaluation_times):\n",
    "    num_examples_train = len(get_dataset(subtask, language, domain, split=\"train\"))\n",
    "    num_examples_dev = len(get_dataset(subtask, language, domain, split=EVALUATION_SET))\n",
    "    records_evaluation_times[i] = (subtask, language, domain, total_time, num_examples_train, num_examples_dev)\n",
    "    \n",
    "# calculate average time per 1000 examples\n",
    "for i, (subtask, language, domain, total_time, num_examples_train, num_examples_dev) in enumerate(records_evaluation_times):\n",
    "    avg_time_per_1000 = (total_time / num_examples_train) * 1000 if num_examples_train > 0 else 0\n",
    "    records_evaluation_times[i] = (subtask, language, domain, total_time, num_examples_train, num_examples_dev, avg_time_per_1000)\n",
    "    \n",
    "# Berechne average evaluation_time für sc und no_sc\n",
    "for i, (subtask, language, domain, total_time, num_examples_train, num_examples_dev, avg_time_per_1000) in enumerate(records_evaluation_times):\n",
    "    # Self Consistency True\n",
    "    filtered_eval_logs_sc = [\n",
    "        log for log in evaluation_logs_sc\n",
    "        if log[\"subtask\"] == subtask and log[\"language\"] == language and log[\"domain\"] == domain\n",
    "    ]\n",
    "    eval_times_sc = [log[\"evaluation_time\"] for log in filtered_eval_logs_sc if \"evaluation_time\" in log]\n",
    "    avg_evaluation_time_sc = sum(eval_times_sc) / len(eval_times_sc) if eval_times_sc else 0\n",
    "    avg_evaluation_time_per_example_sc = (avg_evaluation_time_sc / num_examples_dev) if num_examples_dev > 0 else 0\n",
    "    \n",
    "    # Self Consistency False\n",
    "    filtered_eval_logs_no_sc = [\n",
    "        log for log in evaluation_logs_no_sc\n",
    "        if log[\"subtask\"] == subtask and log[\"language\"] == language and log[\"domain\"] == domain\n",
    "    ]\n",
    "    eval_times_no_sc = [log[\"evaluation_time\"] for log in filtered_eval_logs_no_sc if \"evaluation_time\" in log]\n",
    "    avg_evaluation_time_no_sc = sum(eval_times_no_sc) / len(eval_times_no_sc) if eval_times_no_sc else 0\n",
    "    avg_evaluation_time_per_example_no_sc = (avg_evaluation_time_no_sc / num_examples_dev) if num_examples_dev > 0 else 0\n",
    "    \n",
    "    records_evaluation_times[i] = (subtask, language, domain, total_time, num_examples_train, num_examples_dev, avg_time_per_1000, \n",
    "                                   avg_evaluation_time_sc, avg_evaluation_time_per_example_sc,\n",
    "                                   avg_evaluation_time_no_sc, avg_evaluation_time_per_example_no_sc)\n",
    "    \n",
    "# convert records_evaluation_times to pandas dataframe\n",
    "df_evaluation_times = pd.DataFrame(\n",
    "    records_evaluation_times,\n",
    "    columns=[\"subtask\", \"language\", \"domain\", \"total_time\", \"num_examples_train\", \"num_examples_dev\", \"avg_time_per_1000\", \n",
    "             \"avg_evaluation_time_sc\", \"avg_evaluation_time_per_example_sc\",\n",
    "             \"avg_evaluation_time_no_sc\", \"avg_evaluation_time_per_example_no_sc\"]\n",
    ")   \n",
    "\n",
    "# Erstelle separate DataFrames für jeden Subtask\n",
    "df_evaluation_times_subtask2 = df_evaluation_times[df_evaluation_times[\"subtask\"] == 2].copy()\n",
    "df_evaluation_times_subtask3 = df_evaluation_times[df_evaluation_times[\"subtask\"] == 3].copy()\n",
    "\n",
    "# Funktion zum Hinzufügen der Average-Zeile\n",
    "def add_average_row(df):\n",
    "    avg_row = df.select_dtypes(include=[float, int]).mean()\n",
    "    avg_row[\"language\"] = \"average\"\n",
    "    avg_row[\"domain\"] = \"\"\n",
    "    avg_row[\"subtask\"] = df[\"subtask\"].iloc[0]\n",
    "    avg_df = pd.DataFrame([avg_row])\n",
    "    return pd.concat([df, avg_df], ignore_index=True)\n",
    "\n",
    "# Füge Average-Zeile hinzu\n",
    "df_evaluation_times_subtask2 = add_average_row(df_evaluation_times_subtask2)\n",
    "df_evaluation_times_subtask3 = add_average_row(df_evaluation_times_subtask3)\n",
    "\n",
    "# Formatiere die Zeiten als Ganzzahlen mit \",\" als Tausendertrennzeichen\n",
    "for df in [df_evaluation_times_subtask2, df_evaluation_times_subtask3]:\n",
    "    df[\"total_time\"] = df[\"total_time\"].apply(lambda x: f\"{int(x):,}\" if pd.notna(x) else \"-\")\n",
    "    df[\"avg_time_per_1000\"] = df[\"avg_time_per_1000\"].apply(lambda x: f\"{int(x):,}\" if pd.notna(x) else \"-\")\n",
    "    df[\"num_examples_train\"] = df[\"num_examples_train\"].apply(lambda x: f\"{int(x):,}\" if pd.notna(x) else \"-\")\n",
    "    df[\"num_examples_dev\"] = df[\"num_examples_dev\"].apply(lambda x: f\"{int(x):,}\" if pd.notna(x) else \"-\")\n",
    "    df[\"avg_evaluation_time_sc\"] = df[\"avg_evaluation_time_sc\"].apply(lambda x: f\"{int(x):,}\" if pd.notna(x) else \"-\")\n",
    "    df[\"avg_evaluation_time_per_example_sc\"] = df[\"avg_evaluation_time_per_example_sc\"].apply(lambda x: f\"{x:,.3f}\" if pd.notna(x) else \"-\")\n",
    "    df[\"avg_evaluation_time_no_sc\"] = df[\"avg_evaluation_time_no_sc\"].apply(lambda x: f\"{int(x):,}\" if pd.notna(x) else \"-\")\n",
    "    df[\"avg_evaluation_time_per_example_no_sc\"] = df[\"avg_evaluation_time_per_example_no_sc\"].apply(lambda x: f\"{x:,.3f}\" if pd.notna(x) else \"-\")\n",
    "\n",
    "# Benenne Spalten um\n",
    "for df in [df_evaluation_times_subtask2, df_evaluation_times_subtask3]:\n",
    "    df.rename(columns={\n",
    "        \"total_time\": \"num_seconds_train\",\n",
    "        \"avg_time_per_1000\": \"avg_seconds_train_per_1000\",\n",
    "        \"num_examples_dev\": \"num_examples_evaluate\",\n",
    "        \"avg_evaluation_time_sc\": \"num_seconds_evaluate_sc\",\n",
    "        \"avg_evaluation_time_per_example_sc\": \"num_seconds_evaluate_per_example_sc\",\n",
    "        \"avg_evaluation_time_no_sc\": \"num_seconds_evaluate_no_sc\",\n",
    "        \"avg_evaluation_time_per_example_no_sc\": \"num_seconds_evaluate_per_example_no_sc\"\n",
    "    }, inplace=True)\n",
    "\n",
    "# Ordne Spalten in gewünschter Reihenfolge\n",
    "column_order = [\n",
    "    \"language\",\n",
    "    \"domain\",\n",
    "    \"num_examples_train\",\n",
    "    \"num_seconds_train\",\n",
    "    \"avg_seconds_train_per_1000\",\n",
    "    \"num_examples_evaluate\",\n",
    "    \"num_seconds_evaluate_sc\",\n",
    "    \"num_seconds_evaluate_per_example_sc\",\n",
    "    \"num_seconds_evaluate_no_sc\",\n",
    "    \"num_seconds_evaluate_per_example_no_sc\"\n",
    "]\n",
    "\n",
    "df_evaluation_times_subtask2 = df_evaluation_times_subtask2[column_order]\n",
    "df_evaluation_times_subtask3 = df_evaluation_times_subtask3[column_order]\n",
    "\n",
    "# Zeige die DataFrames an ohne Index\n",
    "from IPython.display import display\n",
    "\n",
    "print(\"Subtask 2:\")\n",
    "display(df_evaluation_times_subtask2)\n",
    "\n",
    "print(\"\\nSubtask 3:\")\n",
    "display(df_evaluation_times_subtask3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4330f6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert eng to English, zho to Chinese, jpn to Japanese, rus to Russian, tat to Tatar, ukr to Ukrainian in both dataframes\n",
    "language_map = {\n",
    "    \"eng\": \"English\",\n",
    "    \"zho\": \"Chinese\",\n",
    "    \"jpn\": \"Japanese\",\n",
    "    \"rus\": \"Russian\",\n",
    "    \"tat\": \"Tatar\",\n",
    "    \"ukr\": \"Ukrainian\",\n",
    "    \"average\": \"Average\"\n",
    "}\n",
    "df_evaluation_times_subtask2.loc[:, \"language\"] = df_evaluation_times_subtask2[\"language\"].map(language_map)\n",
    "df_evaluation_times_subtask3.loc[:, \"language\"] = df_evaluation_times_subtask3[\"language\"].map(language_map)\n",
    "# uppercase first letter of domain in both dataframes\n",
    "df_evaluation_times_subtask2.loc[:, \"domain\"] = df_evaluation_times_subtask2[\"domain\"].str.capitalize()\n",
    "df_evaluation_times_subtask3.loc[:, \"domain\"] = df_evaluation_times_subtask3[\"domain\"].str.capitalize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "617f6702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load \"plots/muster/time.txt\" as text\n",
    "with open(\"plots/muster/time.txt\", \"r\") as f:\n",
    "    time_txt = f.read()\n",
    "\n",
    "# insert the values from df_evaluation_times_subtask2 and df_evaluation_times_subtask3 into time_txt\n",
    "# go from xxxx to xxxx and replace\n",
    "subtask_3_time_list = df_evaluation_times_subtask3.values.flatten().tolist()\n",
    "subtask_2_time_list = df_evaluation_times_subtask2.values.flatten().tolist()\n",
    "\n",
    "time_txt_2 = time_txt\n",
    "\n",
    "for value in subtask_2_time_list:\n",
    "    if value == \"Average\":\n",
    "        continue\n",
    "    time_txt_2 = time_txt_2.replace(\"xxxx\", str(value), 1)\n",
    "    \n",
    "time_txt_3 = time_txt\n",
    "\n",
    "for value in subtask_3_time_list:\n",
    "    if value == \"Average\":\n",
    "        continue\n",
    "    time_txt_3 = time_txt_3.replace(\"xxxx\", str(value), 1)\n",
    "\n",
    "with open(\"plots/time_subtask2.txt\", \"w\") as f:\n",
    "    f.write(time_txt_2)\n",
    "\n",
    "with open(\"plots/time_subtask3.txt\", \"w\") as f:\n",
    "    f.write(time_txt_3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vllm013",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
