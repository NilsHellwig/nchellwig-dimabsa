{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "509021e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBTASKS = [3, 2]\n",
    "LANGUAGES = [\"eng\", \"jpn\", \"rus\", \"tat\", \"ukr\", \"zho\"]\n",
    "DOMAINS = [\"restaurant\", \"laptop\", \"hotel\", \"finance\"]\n",
    "N_SEEDS_RUNS = 1\n",
    "STRATEGY = \"train_split\"  # \"pred_dev\" oder \"train_split\"\n",
    "N_SPLITS = 5  # Anzahl der 80/20 Splits f√ºr train_split\n",
    "EPOCHS = [5, 10, 15]\n",
    "LLMs = [\"unsloth/gemma-3-4b-it-bnb-4bit\", \"unsloth/Qwen3-4B-Instruct-2507-unsloth-bnb-4bit\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4439be12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from evaluate import evaluate_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42514aeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TP': 364.05294198624887,\n",
       " 'FP': 300,\n",
       " 'FN': 349,\n",
       " 'cPrecision': 0.5260880664541169,\n",
       " 'cRecall': 0.4912995168505383,\n",
       " 'cF1': 0.508099011844032}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_predictions(subtask, language, domain, llm_name, num_epochs, split_idx):\n",
    "    # /home/hellwig/ur-mi-nch/results/results_train_split/subtask_3/pred_eng_restaurant_gemma-3-4b-it-bnb-4bit_epochs5_split0.jsonl\n",
    "    llm_name_formatted = llm_name.split(\"/\")[-1]\n",
    "    path = f\"results/results_train_split/subtask_{subtask}/pred_{language}_{domain}_{llm_name_formatted}_epochs{num_epochs}_split{split_idx}.jsonl\"\n",
    "    predictions = []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line)\n",
    "            predictions.append(data)\n",
    "    return predictions\n",
    "\n",
    "def load_ground_truth(subtask, language, domain):\n",
    "    # task-dataset/track_a/subtask_2/eng/eng_laptop_train_alltasks.jsonl\n",
    "    path = f\"task-dataset/track_a/subtask_{subtask}/{language}/{language}_{domain}_train_alltasks.jsonl\"\n",
    "    ground_truth = []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line)\n",
    "            ground_truth.append(data)\n",
    "    return ground_truth\n",
    "\n",
    "labels = load_ground_truth(3, \"eng\", \"restaurant\")\n",
    "preds = load_predictions(3, \"eng\", \"restaurant\", \"unsloth/gemma-3-4b-it-bnb-4bit\", 5, 0)\n",
    "# filter preds to only include those in labels\n",
    "preds_dict = {pred['ID']: pred for pred in preds}\n",
    "labels_filtered = []\n",
    "preds_filtered = []\n",
    "for label in labels:\n",
    "    if label['ID'] in preds_dict:\n",
    "        labels_filtered.append(label)\n",
    "        preds_filtered.append(preds_dict[label['ID']])\n",
    "\n",
    "evaluate_predictions(labels_filtered, preds_filtered, task=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5fd28bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87ba62e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>Domain</th>\n",
       "      <th>Subtask</th>\n",
       "      <th>LLM</th>\n",
       "      <th>Epochs</th>\n",
       "      <th>Avg_TP</th>\n",
       "      <th>Avg_cPrecision</th>\n",
       "      <th>Avg_cRecall</th>\n",
       "      <th>Avg_cF1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eng</td>\n",
       "      <td>restaurant</td>\n",
       "      <td>3</td>\n",
       "      <td>unsloth/gemma-3-4b-it-bnb-4bit</td>\n",
       "      <td>5</td>\n",
       "      <td>364.052942</td>\n",
       "      <td>0.526088</td>\n",
       "      <td>0.491300</td>\n",
       "      <td>0.508099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rus</td>\n",
       "      <td>restaurant</td>\n",
       "      <td>3</td>\n",
       "      <td>unsloth/gemma-3-4b-it-bnb-4bit</td>\n",
       "      <td>5</td>\n",
       "      <td>227.278735</td>\n",
       "      <td>0.472513</td>\n",
       "      <td>0.452746</td>\n",
       "      <td>0.462419</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Language      Domain  Subtask                             LLM  Epochs  \\\n",
       "0      eng  restaurant        3  unsloth/gemma-3-4b-it-bnb-4bit       5   \n",
       "1      rus  restaurant        3  unsloth/gemma-3-4b-it-bnb-4bit       5   \n",
       "\n",
       "       Avg_TP  Avg_cPrecision  Avg_cRecall   Avg_cF1  \n",
       "0  364.052942        0.526088     0.491300  0.508099  \n",
       "1  227.278735        0.472513     0.452746  0.462419  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for language in LANGUAGES:\n",
    "    for subtask in SUBTASKS:\n",
    "        for domain in DOMAINS:\n",
    "            for seed_run in range(N_SEEDS_RUNS):\n",
    "                for llm in LLMs:\n",
    "                    for num_epochs in EPOCHS:\n",
    "                        key = (language, domain, subtask, llm, num_epochs)\n",
    "                        results[key] = [] \n",
    "                        \n",
    "                        for split_idx in range(N_SPLITS):\n",
    "                            # Load predictions\n",
    "                            try:\n",
    "                              predictions = load_predictions(subtask, language, domain, llm, num_epochs, split_idx)\n",
    "                            except FileNotFoundError:\n",
    "                              continue\n",
    "                            # Load ground truth\n",
    "                            ground_truth = load_ground_truth(subtask, language, domain)\n",
    "                            # Filter predictions and ground truth to only include matching IDs\n",
    "                            preds_dict = {pred['ID']: pred for pred in predictions}\n",
    "                            labels_filtered = []\n",
    "                            preds_filtered = []\n",
    "                            for label in ground_truth:\n",
    "                                if label['ID'] in preds_dict:\n",
    "                                    labels_filtered.append(label)\n",
    "                                    preds_filtered.append(preds_dict[label['ID']])\n",
    "                                    \n",
    "                            for example in labels_filtered:\n",
    "                                # change key Quadruplet to Triplet if subtask == 2\n",
    "                                if subtask == 2 and 'Quadruplet' in example:\n",
    "                                    example['Triplet'] = example.pop('Quadruplet')\n",
    "                                    \n",
    "                            \n",
    "                            # Evaluate\n",
    "                            eval_result = evaluate_predictions(labels_filtered, preds_filtered, task=subtask)\n",
    "                            results[key].append(eval_result)\n",
    "                            \n",
    "# Aggregate results over splits\n",
    "final_results = {}\n",
    "for key, evals in results.items():\n",
    "    if len(evals) == 0:\n",
    "        continue\n",
    "    avg_TP = sum(e['TP'] for e in evals) / len(evals)\n",
    "    avg_cPrecision = sum(e['cPrecision'] for e in evals) / len(evals)\n",
    "    avg_cRecall = sum(e['cRecall'] for e in evals) / len(evals)\n",
    "    avg_cF1 = sum(e['cF1'] for e in evals) / len(evals)\n",
    "    final_results[key] = {\n",
    "        'avg_TP': avg_TP,\n",
    "        'avg_cPrecision': avg_cPrecision,\n",
    "        'avg_cRecall': avg_cRecall,\n",
    "        'avg_cF1': avg_cF1\n",
    "    }\n",
    "    \n",
    "# create table with final results using pandas\n",
    "import pandas as pd\n",
    "final_results_df = pd.DataFrame.from_dict(final_results, orient='index')\n",
    "final_results_df.reset_index(inplace=True)\n",
    "final_results_df.columns = ['Language', 'Domain', 'Subtask', 'LLM', 'Epochs', 'Avg_TP', 'Avg_cPrecision', 'Avg_cRecall', 'Avg_cF1']\n",
    "final_results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unsloth_training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
